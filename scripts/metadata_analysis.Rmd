## Load libraries
```{r cache=FALSE, include=TRUE, echo=FALSE, message=FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE, cache=FALSE, fig.path=paste0('./Figures_', Sys.Date(), '/')) 
# utility
#library(shiny)
library(tibble)
library(data.table)
library(devtools)
library(knitr)
library(tidyr)
library(reshape2)
library(dplyr)
# visualization
library(ggplot2)
library(pander)
library(DT)
library(gridExtra)
library(adegraphics)
library(stats)
#library(smatr)
library(caret)
library(randomForest)
library(ROCR)

library(exactRankTests)
library(nlme)
library(compositions)
#git clone from: https://github.com/FrederickHuangLin/ANCOM.git
#source("C:/Users/ctata/ANCOM/scripts/ancom_v2.1.R")
#library(ggpubr)

# data analysis

#Need biocondutor (installation method may have changed recently)
#if (!requireNamespace("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")

#BiocManager::install("vegan")
library(vegan)
#BiocManager::install("metagenomeSeq")
library(metagenomeSeq)
#BiocManager::install("DESeq2")
library(DESeq2)
#BiocManager::install("biomformat")
library(biomformat)
#BiocManager::install("phyloseq")
library(phyloseq)

sgColorPalette = c("#84CF04","#01B5BB","#E50E63","#6D7272","#8F389E",
                     "#DF8236","#036B6B","#F1BA2F","#9F832D","#94E804",
                     "#01D4DB","#FAC131","#B0B8B8","#F08C3A","#FF106E",
                     "#B948CC","#05B5B5","#CFAA3A")
```

## All parameters
### File paths
```{r filepaths}
##### If you have M3 google drive and bitbucket repo on your local machine, 
##### you only need to change two parameters below
# M3-shared google drive location
#M3folder_loc_for_ps='/Google Drive/M3-shared/V4/Data/200312_ASVdata8_updateAsteria/Phyloseq_objects/age_filtered_PS_objects/ps_notnorm_age_filter_complete_family.rds'

# Loading ps using actual filepath for analysis (To change depending on the user)
ps_not_norm_comp <- readRDS("../data/ps_not_norm_age_filter_complete_family.rds")

## Output data location (subject to change)
#output_data=paste0(M3folder_loc, 'Data/V4/180808_ASVdata4/OutputData_Agefiltered/')
output_data <- "../results/"

```

### Cutoff parameters
```{r cutoff}
# chisquare test cutoff (for diet questionnare results significance)
chisq_cut=0.05
```


# Summarize metadata

```{r sum_meta_fun}
# chisquared test function
run_chisq_test <- function(ps, metacol){
  # ps: phyloseq object
  # metacol: metadata column name to test
  metaDF <- data.frame(sample_data(ps))
  # remove NAs, for some reason, some NA are recorded as a text!
  submetaDF=metaDF[!is.na(metaDF[, metacol]), ]
  submetaDF=submetaDF[submetaDF[, metacol]!='NA', ]
  submetaDF=submetaDF[submetaDF[, metacol]!='', ]   # also remove blank
  # chisquared test
  chisq_res=chisq.test(table(submetaDF[, metacol], submetaDF[, 'phenotype']))
  # extract results
  resDT=data.table(chisq_res$observed)
  # dcast for printing
  resDT <- data.table(dcast(resDT, V1 ~ V2, value.var='N'))
  resDT <- resDT[, testvar:=metacol]
  resDT <- resDT[, chisq_p:=chisq_res$p.value]
  
  return(resDT[, list(testvar, category=V1, A, N, chisq_p)])
}

# composition plot function
plot_composition <- function(chisq_resDT, var_name){
  # chisq_resDT: 4 columns. testvar, category, A, N, chisq_p
  plotDT=melt(chisq_resDT, id.vars=c('testvar', 'category', 'chisq_p'))
  p=ggplot(data=plotDT[plotDT$testvar==var_name], aes(x=variable, y=value, fill=category))+
    geom_bar(stat="identity")+
    xlab('')+ylab('Number of sample')+
    ggtitle(var_name)+
    theme_minimal()+
    theme(legend.title=element_blank(), legend.position="bottom", axis.text.x=element_text(vjust=1, hjust=1))+
    scale_fill_manual(values=sgColorPalette)
  print(p)
}
```

## Demographics

## fix metadata and remove samples that are too young or have diagnostic discrepancies
```{r fix}

#fixing the mapping file for stats by adding categorical vs non catergorical
#Remove Breastfed and their families
breast_fed <- c("089_A","054_N", "158_N" )

b_fed<-unique(ps_not_norm_comp@sam_data$Family.group.ID[which(ps_not_norm_comp@sam_data$Host.Name %in% breast_fed)])

#remove the whole family
for (i in b_fed){
  ps_not_norm_comp<- prune_samples(ps_not_norm_comp@sam_data$Family.group.ID != i, ps_not_norm_comp)

}

#Remove Possible Contradictions and their families
possible_phen_contra <- c("020_A","131_A", "184_A" )

p_con<-unique(ps_not_norm_comp@sam_data$Family.group.ID[which(ps_not_norm_comp@sam_data$Host.Name %in% possible_phen_contra)])

#remove the whole family
for (i in p_con){
  ps_not_norm_comp<- prune_samples(ps_not_norm_comp@sam_data$Family.group.ID != i, ps_not_norm_comp)

}

metadata_ok<-sample_data(ps_not_norm_comp)
write.csv(metadata_ok, "../data/sam_data.csv")
map <- read.csv("../data/sam_data.csv", row.names = 1)
meta_cat <- read.csv("../data/updated_metacategories.csv", row.names = 1)
meta_cat = meta_cat[rownames(meta_cat) %in% colnames(map), ]

for (i in rownames(meta_cat)[meta_cat$permanova != FALSE]){
  print(i)
 if (meta_cat[i, ]$permanova == "Categorical") {
    map[,i] <- as.factor(map[,i])
 } else {
    map[,i] <- as.numeric(map[,i])
 }
}


makeFieldsNumeric <- function(map){
  handleNAs <- function(vec){
    vec[vec == ""] <- "NA"
    vec[is.na(vec)] <- "NA"
    return(vec)
  }
  
  map$Stool.frequency <- handleNAs(as.character(map$Stool.frequency))
  map$Stool.frequency[as.character(map$Stool.frequency) == "Less than 1"] = 0
  map$Stool.frequency[as.character(map$Stool.frequency) == "5 or more"] = 5
  map$Dairy..consumption.frequency...longitudinal.[map$Dairy..consumption.frequency...longitudinal. == 5] <- "3-4 meals per week"
  #map$LR2[map$LR2 == "1 (ASD)"] = 1
  #map$LR2[map$LR2 == "0 (non-ASD"] = 0
  
  
  freq_dict_2 <- list("Never" = 0, "Rarely" = 1, "Occasionally" = 2, "Regularly" = 3, "Weekly" = 4, "weekly" = 4,
                      "Several time weekly" = 5, "Several times weekly" = 5, "Daily" = 6, "NA" = NA)
  dict_2_items <- c("Whole.grain..consumption.frequency.", "Fermented.vegetable..consumption.frequency.", "Dairy..consumption.frequency.","Meat..consumption.frequency." , "Fruit..consumption.frequency.", "Meals.prepared.at.home..consumption.frequency.",   "Ready.to.eat.meals..consumption.frequency.", "Red.meat..consumption.frequency.", "Olive.oil.used.in.cooking..M3.", "Seafood..consumption.frequency.",   "Sweetened.drink..consumption.frequency.", "Vegetable..consumption.frequency.",
                    "Restaurant.prepared.meals..consumption.frequency.", "Sugary.food..consumption.frequency.", "Probiotic..consumption.frequency.", "Vitamin.B.complex.supplement..consumption.frequency.", "Vitamin.D..consumption.frequency.")
  for(item in dict_2_items){
    print(item)
    tmp <- rep(NA, nrow(map))
    freqs <- handleNAs(map[,item])
    numeric_rep <- unlist(freq_dict_2[freqs])
    print(paste("Numeric rep length: ", length(numeric_rep)))
    print(sum(!is.na(freqs)))
    tmp[!is.na(freqs)] <- as.numeric(numeric_rep)  
    map[ , item] <- tmp
  }
  
  
  freq_dict_1 <- list("Never or less than once per week" = 0, "3-4 meals per week" = 1, "5" = 2, "7-10 meals per week" = 3, "Almost every meal" = 4, "NA" = NA)
  dict_1_items <- c("Starchy.food..consumption.frequency...longitudinal.", "Meats.and.seafood..consumption.frequency...longitudinal.", "Bread..consumption.frequency...longitudinal.", "Dairy..consumption.frequency...longitudinal.", "Dietary.fat.and.oil..consumption.frequency...longitudinal.", "Vegetable..consumption.frequency...longitudinal.", 
                    "Fruit..consumption.frequency...longitudinal.")
  for(item in dict_1_items){
    print(item)
    tmp <- rep(NA, nrow(map))
    freqs <- handleNAs(map[ , item])
    numeric_rep <- unlist(freq_dict_1[freqs])
    print(paste("Numeric rep length: ", length(numeric_rep)))
    print(sum(!is.na(freqs)))
    tmp[!is.na(freqs)] <- as.numeric(numeric_rep)  
    map[ , item] <- tmp
  }
  
  #may add more, but these variable only apply to phenotype for autism
    freq_dict_2 <- list("Able to speak fluently" = 3,"Phrase speech"=2, "Single word speech"=1, "Little to no speech" = 0, "Able to have conversation" = 3, "Limited conversation ability" = 2, "Difficulty with conversation" = 1, "Cannot have a conversation" = 0,"Understands about half of words" = 1, "Understands few or no words"= 0, "Understands many words" = 2,  "Understands most words"= 3, "Understands nearly all words" = 4 ,"NA" = NA)
  dict_2_items <- c("Language.ability.and.use", "Conversation.ability", "Understands.speech")
  for(item in dict_2_items){
    print(item)
    tmp <- rep(NA, nrow(map))
    freqs <- handleNAs(map[ , item])
    numeric_rep <- unlist(freq_dict_2[freqs])
    print(paste("Numeric rep length: ", length(numeric_rep)))
    print(sum(!is.na(freqs)))
    tmp[!is.na(freqs)] <- as.numeric(numeric_rep)  
    map[ , item] <- tmp
  }
  
  #may add more
    freq_dict_3 <- list( "Never" = 1, "Sometimes" = 2, "Regularly" = 3,  "NA" = 1, "Constant sleep difficulties" = 3,"Some sleep difficulties" = 2, "Healthy sleep pattern" = 1, "Highly sensitive to typical sounds" = 3,  "Sensitive to typical sounds" = 2, "Not bothered by typical sounds" = 1, "No self-injurious behavior" = 1,"Mild self-harming behavior" = 2, "Dangerous or frequent self-harming behavior" = 3,  "No issues" = 1, "Continuous" = 3, "No elevated anxiety" = 1, "Somewhat elevated anxiety" = 2, "Elevated anxiety" = 3)
  dict_3_items <- c("Recent.anxiety..caretaker.reported.")
  for(item in dict_3_items){
    print(item)
    tmp <- rep(NA, nrow(map))
    freqs <- handleNAs(map[ , item])
    numeric_rep <- unlist(freq_dict_3[freqs])
    print(paste("Numeric rep length: ", length(numeric_rep)))
    print(sum(!is.na(freqs)))
    tmp[!is.na(freqs)] <- as.numeric(numeric_rep)
    tmp[is.na(tmp)] <- 1
    map[ , item] <- tmp
  }
  
  map <- map[!duplicated(map$Biospecimen.Barcode), ]
  rownames(map) <- map$Biospecimen.Barcode
  map$Stool.frequency <- as.numeric(map$Stool.frequency)
  return(map)

}

dict_1_items <- c("Starchy.food..consumption.frequency...longitudinal.", "Meats.and.seafood..consumption.frequency...longitudinal.", "Bread..consumption.frequency...longitudinal.", "Dairy..consumption.frequency...longitudinal.", "Dietary.fat.and.oil..consumption.frequency...longitudinal.", "Vegetable..consumption.frequency...longitudinal.", 
                    "Fruit..consumption.frequency...longitudinal.")
dict_2_items <- c("Language.ability.and.use", "Conversation.ability", "Understands.speech")


map<-makeFieldsNumeric(map)


map_levels<-sapply(map, levels)
map_levelscount<-sapply(map_levels, length)
mapnotfac <- names(map_levelscount[which(map_levelscount >= 18)])

for (i in mapnotfac){
  map[,i]<-as.character(map[,i])
}

#Round years
map$Age..years. <-round(map$Age..years.)
sample_data(ps_not_norm_comp) <- map

#remove samples that are too young and their paired sibling
#tooyoung <-ps_not_norm_comp@sam_data$Family.group.ID[which(ps_not_norm_comp@sam_data$Age..months. < 24)]

#family 65 should be removed according to >24 months criteria
#ps_not_norm_comp<- prune_samples(ps_not_norm_comp@sam_data$Family.group.ID != unique(tooyoung), ps_not_norm_comp)

#List of individuals that were reported w/ autism, but was not classified as such through MARA and/or video classifier
#pheno_contrad <-read.csv("../data/phenotype_contradictions.csv")
#contradicting<-unique(ps_not_norm_comp@sam_data$Family.group.ID[which(ps_not_norm_comp@sam_data$Host.Name %in% as.character(pheno_contrad$host_name))])

#remove the whole family
#for (i in contradicting){
#  ps_not_norm_comp<- prune_samples(ps_not_norm_comp@sam_data$Family.group.ID != i, ps_not_norm_comp)

#}

```


```{r}
#add season during collection
ps_not_norm_comp@sam_data$Season <- gsub("-01-", "Winter", ps_not_norm_comp@sam_data$Biospecimen.Date.Collected)
wint <- c("-02-", "-12-")
for (i in wint){
ps_not_norm_comp@sam_data$Season <- gsub(i, "Winter", ps_not_norm_comp@sam_data$Season)
}

spring <- c("-03-", "-04-", "-05-")
for (i in spring){
ps_not_norm_comp@sam_data$Season <- gsub(i, "Spring", ps_not_norm_comp@sam_data$Season)
}

summer <- c("-06-", "-07-", "-08-")
for (i in summer){
ps_not_norm_comp@sam_data$Season <- gsub(i, "Summer", ps_not_norm_comp@sam_data$Season)
}

fall<- c("-09-", "-10-", "-11-")
for (i in fall){
ps_not_norm_comp@sam_data$Season <- gsub(i, "Fall", ps_not_norm_comp@sam_data$Season)
}

ps_not_norm_comp@sam_data$Season <- gsub("2018","", ps_not_norm_comp@sam_data$Season)
ps_not_norm_comp@sam_data$Season <- gsub("2017","", ps_not_norm_comp@sam_data$Season)

for (i in c("1","2","3", "4", "5", "6", "7", "8", "9", "0")){
ps_not_norm_comp@sam_data$Season <- gsub(i, "", ps_not_norm_comp@sam_data$Season)
}
ps_not_norm_comp@sam_data$Season <- as.factor(ps_not_norm_comp@sam_data$Season)

ps_not_norm_comp@sam_data$Annual.household.income_rank <- gsub("150001-200000", 5, ps_not_norm_comp@sam_data$Annual.household.income)

ps_not_norm_comp@sam_data$Annual.household.income_rank <- gsub("More than 200000", 6, ps_not_norm_comp@sam_data$Annual.household.income_rank)

ps_not_norm_comp@sam_data$Annual.household.income_rank <- gsub("Less than 20000", 1, ps_not_norm_comp@sam_data$Annual.household.income_rank)

ps_not_norm_comp@sam_data$Annual.household.income_rank <- gsub("20001-40000", 2, ps_not_norm_comp@sam_data$Annual.household.income_rank)

ps_not_norm_comp@sam_data$Annual.household.income_rank <- gsub("40001-80000", 3, ps_not_norm_comp@sam_data$Annual.household.income_rank)

ps_not_norm_comp@sam_data$Annual.household.income_rank <- gsub("80001-150001", 4, ps_not_norm_comp@sam_data$Annual.household.income_rank)

ps_not_norm_comp@sam_data$Annual.household.income_rank <- as.numeric(ps_not_norm_comp@sam_data$Annual.household.income_rank)


#round off year
ps_not_norm_comp@sam_data$Age..years.<-round(ps_not_norm_comp@sam_data$Age..years.)

metadata_ok<-ps_not_norm_comp@sam_data



```


### Run a Chi squared test on all categorical variables between ASD and NT samples
```{r sex, fig.width=5, fig.height=4}

#now let's only run the categorical values for chi square and remove the first column which are not metadata 
fac_cat <- colnames(metadata_ok)[unlist(lapply(metadata_ok, is.factor))]
#removing the first 13 columns, since it's not metadata and the last one which is phenotype  
fac_cat<-fac_cat[-which(fac_cat %in% c("phenotype", "Host.disease.status"))]
#finally removing the ones that were only asked for the children with ASD, or only have one factor & NA, or only present in one phen
fac_cat<-fac_cat[-which(fac_cat %in% c("Behavior.video.submitted..M3.","Language.ability.and.use","Conversation.ability","Understands.speech","Plays.imaginatively.when.alone","Plays.imaginatively.with.others","Plays.in.a.group.with.others","Eye.contact.finding","Childhood.behavioral.development.finding","Repetitive.motion","Picks.up.objects.to.show.to.others","Sleep.pattern.finding","Response.to.typical.sounds","Self.injurious.behavior.finding","Gastrointestinal.problems..M3.", "Imitation.behavior", "Other.stool.sample.collection.method.explained..M3.", "Flu.shot.in.the.last..MFlu.shot.in.the.last..M3.", "Pica.disease", "Additional.info.affecting.microbiome..M3.", "Dietary.restrictions.details..M3.", "Pet.bird"))]

sample_timepoint_dependent_factors <- c("GI.symptoms.within.3.months..M3.", "GI.issues.this.week..M3.", "GI.issues.one.month.ago..M3.", "GI.issues.two.months.ago..M3.", "GI.issues.three.months.ago..M3.", "Stool.sample.collection.method..M3.", "Problems.collecting.stool.sample..M3.", "Recently.ill" , "Season" , "Fever", "Travel.to.country", "Other.symptoms.this.week..M3.", "Small.pet.rodent")

#Also remove the ones with only one factor (no chi-square possible)
#now running the chisquare on all categorical values 
chisquare_p.val=c()
names_chisquare_p.val=c()
all_chisquare=list()
chi_list<-names(map_levelscount)[map_levelscount > 1]
chi_list <-chi_list[-c(1:3)]
chi_list<-chi_list[-which(chi_list %in% c("Behavior.video.submitted..M3.","Language.ability.and.use","Conversation.ability","Understands.speech","Plays.imaginatively.when.alone","Plays.imaginatively.with.others","Plays.in.a.group.with.others","Eye.contact.finding","Childhood.behavioral.development.finding","Repetitive.motion","Picks.up.objects.to.show.to.others","Sleep.pattern.finding","Response.to.typical.sounds","Self.injurious.behavior.finding","Gastrointestinal.problems..M3.", "Imitation.behavior", "Other.stool.sample.collection.method.explained..M3.", "Flu.shot.in.the.last..MFlu.shot.in.the.last..M3.", "Pica.disease", "Additional.info.affecting.microbiome..M3.", "Dietary.restrictions.details..M3.", "Pet.bird", "Host.disease.status", "phenotype", "LR6.prediction..M3.", "LR10.prediction..M3.", "LR5.prediction..M3."))]

chi_list_constant <- chi_list<-chi_list[-which(chi_list %in% sample_timepoint_dependent_factors)]
#Run chi on all for constant
ps_not_norm<-subset_samples(ps_not_norm_comp, Within.study.sampling.date == "Timepoint 1")
for (i in 1:length(chi_list_constant)){
    tmp<-run_chisq_test(ps_not_norm, chi_list_constant[i])
    chisquare_p.val<-c(chisquare_p.val,min(tmp$chisq_p))
    names_chisquare_p.val<-c(names_chisquare_p.val,chi_list_constant[i])
    all_chisquare[[i]]<-tmp
}
names(chisquare_p.val)<-names_chisquare_p.val
names(all_chisquare) <-chi_list_constant

# p-value correction
chisquare_p.val<-p.adjust(chisquare_p.val)
sig_catvar <-chisquare_p.val[chisquare_p.val < 0.05]

length(sig_catvar)
sig_catvar


chisquare_p.val2=c()
names_chisquare_p.val2=c()
all_chisquare2=list()

for (i in 1:length(sample_timepoint_dependent_factors)){
    tmp<-run_chisq_test(ps_not_norm_comp, sample_timepoint_dependent_factors[i])
    chisquare_p.val2<-c(chisquare_p.val2,min(tmp$chisq_p))
    names_chisquare_p.val2<-c(names_chisquare_p.val2,sample_timepoint_dependent_factors[i])
    all_chisquare2[[i]]<-tmp
}
names(chisquare_p.val2)<-names_chisquare_p.val2
names(all_chisquare2) <-sample_timepoint_dependent_factors

# p-value correction
chisquare_p.val2<-p.adjust(chisquare_p.val2)
sig_catvar2 <-chisquare_p.val2[chisquare_p.val2 < 0.05]

length(sig_catvar2) 
#sig_catvar2
names(sig_catvar2) 

sig_catvar <- c(sig_catvar, sig_catvar2)
#vizualisation of the results 
#select only the signififcant ones
all_chisquare<-all_chisquare[names(all_chisquare) %in% names(sig_catvar)]
all_chisquare2<-all_chisquare2[names(all_chisquare2) %in% names(sig_catvar2)]
all_chisquare<-append(all_chisquare, all_chisquare2)
#save this into a csv
write.csv(format(sig_catvar, digits=2), file=paste0(output_data,"Xsqr_05.csv"), quote=F)
# plot one example out of 29 
plot_composition(all_chisquare[1], names(all_chisquare)[1])

#perhaps not surprisingly , many of variables that are significantly different between ASD and NT conditions are lifestyle choices presumably made by the parents. Things like dietary regime, dietary restrictions, and dietary supplements
```

###McNemar for Recent anxiety

```{r}
metadata_ok$Anxiety<-gsub("1", "0" ,metadata_ok$Recent.anxiety..caretaker.reported.)
metadata_ok$Anxiety<-gsub("2", "1", metadata_ok$Anxiety)
metadata_ok$Anxiety<-gsub("3", "1", metadata_ok$Anxiety)

metadata_ok$High_Anxiety<-gsub("1", "0" ,metadata_ok$Recent.anxiety..caretaker.reported.)
metadata_ok$High_Anxiety<-gsub("2", "0", metadata_ok$High_Anxiety)
metadata_ok$High_Anxiety<-gsub("3", "1", metadata_ok$High_Anxiety)

anx<-table(metadata_ok[,c("Anxiety", "phenotype")])
highanx<-table(metadata_ok[,c("High_Anxiety", "phenotype")])

table(metadata_ok[,c("Recent.anxiety..caretaker.reported.", "phenotype")])
table(metadata_ok[,c("Anxiety", "phenotype")])

mcnemar_test(anx)
mcnemar.test(highanx)


```


#Run a wilcoxon rank sum test or t test as appropriate on all the numerical variables between ASD and NT cases
```{r}
map_num<-sapply(map, is.numeric)
num_cat <- colnames(map[,as.vector(which(map_num == TRUE))])
num_cat <- num_cat[-c(1:3)]
num_cat <- num_cat[-which(num_cat %in% c("Language.ability.and.use", "Conversation.ability", "Understands.speech", "Mobile.Autism.Risk.Assessment.Score", "Number.of.small.pet.herbivores", "Number.of.small.pet.rodents", "phenotype_num", "Number.of.pet.birds", "LR6.probability.not.ASD..M3." ,"LR6.probability.ASD..M3." ,"LR10.probability.not.ASD..M3." ,"LR10.probability.ASD..M3.", "LR5.probability.not.ASD..M3.", "LR5.probability.ASD..M3."))]

num_cat_timepoint_dependent <- c(dict_1_items, "Length.of.recent.foreign.travel", "Recent.anxiety..caretaker.reported.")

#Testing to see if numerical variables differ in means using wilcox or t-tests
tmp<-shapiro.test(map[,num_cat[1]])
  if (tmp$p.value <= 0.05) {
    res<-wilcox.test(as.formula(paste(num_cat[1], "~ phenotype")), data=map[which(map$Within.study.sampling.date == "Timepoint 1"),], var.equal = FALSE)
    tab<-tibble(num_cat[1], res$p.value, "wilcox")
    colnames(tab) <- c("Var", "p.value", "Type")
    numerical_test_btwn_pheno <- tab
  }else{
    res<-t.test(as.formula(paste(num_cat[1], "~ phenotype")), data=map[which(map$Within.study.sampling.date == "Timepoint 1"),])
    tab<-tibble(num_cat[1], res$p.value, "t.test")
    colnames(tab) <- c("Var", "p.value", "Type")
    numerical_test_btwn_pheno <- tab
  }


for (i in num_cat[c(-1)]) {
  tmp<-shapiro.test(map[,i])
  if (tmp$p.value <= 0.05) {
    res<-wilcox.test(as.formula(paste(i, "~ phenotype")), data=map[which(map$Within.study.sampling.date == "Timepoint 1"),], var.equal = FALSE)
    tab<-tibble(i, res$p.value, "wilcox")
    colnames(tab) <- c("Var", "p.value", "Type")
    numerical_test_btwn_pheno <-rbind(numerical_test_btwn_pheno, tab)
  }else{
    res<-t.test(as.formula(paste(i, "~ phenotype")), data=map[which(map$Within.study.sampling.date == "Timepoint 1"),])
    tab<-tibble(i, res$p.value, "t.test")
    colnames(tab) <- c("Var", "p.value", "Type")
    numerical_test_btwn_pheno <-rbind(numerical_test_btwn_pheno, tab)
  }
}


numerical_test_btwn_pheno$p.value<-p.adjust(numerical_test_btwn_pheno$p.value)
sig_numvar<-numerical_test_btwn_pheno[which(numerical_test_btwn_pheno$p.value <= 0.05),]


num_cat<-num_cat[num_cat %in% num_cat_timepoint_dependent]
#Testing to see if numerical variables differ in means using wilcox or t-tests with others 
tmp<-shapiro.test(map[,num_cat[1]])
  if (tmp$p.value <= 0.05) {
    res<-wilcox.test(as.formula(paste(num_cat[1], "~ phenotype")), data=map, var.equal = FALSE)
    tab<-tibble(num_cat[1], res$p.value, "wilcox")
    colnames(tab) <- c("Var", "p.value", "Type")
    numerical_test_btwn_pheno <- tab
  }else{
    res<-t.test(as.formula(paste(num_cat[1], "~ phenotype")), data=map)
    tab<-tibble(num_cat[1], res$p.value, "t.test")
    colnames(tab) <- c("Var", "p.value", "Type")
    numerical_test_btwn_pheno <- tab
  }


for (i in num_cat[c(-1)]) {
  tmp<-shapiro.test(map[,i])
  if (tmp$p.value <= 0.05) {
    res<-wilcox.test(as.formula(paste(i, "~ phenotype")), data=map, var.equal = FALSE)
    tab<-tibble(i, res$p.value, "wilcox")
    colnames(tab) <- c("Var", "p.value", "Type")
    numerical_test_btwn_pheno <-rbind(numerical_test_btwn_pheno, tab)
  }else{
    res<-t.test(as.formula(paste(i, "~ phenotype")), data=map)
    tab<-tibble(i, res$p.value, "t.test")
    colnames(tab) <- c("Var", "p.value", "Type")
    numerical_test_btwn_pheno <-rbind(numerical_test_btwn_pheno, tab)
  }
}


numerical_test_btwn_pheno$p.value<-p.adjust(numerical_test_btwn_pheno$p.value)
sig_numvar2<-numerical_test_btwn_pheno[which(numerical_test_btwn_pheno$p.value <= 0.05),]

sig_numvar<-rbind(sig_numvar2, sig_numvar)

write.csv(sig_numvar, "../results/table_num_wilcoxon_or_ttest.csv") 

num_confounds_all <- sig_numvar$Var
saveRDS(num_confounds_all, "../results/numeric_confounds_wilcoxon_or_ttest.rds") 

all_confounds<-c(names(sig_catvar), num_confounds_all )
write.csv(all_confounds, "../all_confounds.csv")


# plot
ggplot(data=sample_data(ps_not_norm_comp), aes(x=phenotype, y=Bread..consumption.frequency...longitudinal., fill=phenotype))+
  geom_boxplot(width=0.7, outlier.colour='white')+
  geom_jitter(size=1, position=position_jitter(width=0.1))+
  xlab('')+ylab('')+
  scale_fill_manual(values=sgColorPalette)+
  theme_minimal()


```



### Racial.group
```{r race2, fig.width=5, fig.height=4}
# print number table
table(sample_data(ps_not_norm_comp)$Racial.group, sample_data(ps_not_norm_comp)$Biological.sex)
# run chisquared test
race=run_chisq_test(ps_not_norm_comp, 'Racial.group')
# print results
pander(race)
# plot
#plot_composition(race, var_name = 'Racial.group')
#will plot manually since plot_composition() isnt working for race right now
plotDT=melt(race, id.vars=c('testvar', 'category', 'chisq_p'))
  p=ggplot(data=plotDT, aes(x=variable, y=value, fill=category))+
    geom_bar(stat="identity")+
    xlab('')+ylab('Number of sample')+
    ggtitle('Racial.group')+
    theme_minimal()+
    theme(legend.title=element_blank(), legend.position="bottom", axis.text.x=element_text(vjust=1, hjust=1))+
    scale_fill_manual(values=sgColorPalette)
  print(p)


# % table
race_prop=prop.table(as.matrix(race[, .(A, N)]), margin=2)*100
row.names(race_prop) <- race$category
pander(race_prop)

# write
write.csv(race_prop, file=paste0(output_data, 'Race.csv'))
```



### Check whether there is a large age discrepancy between ASD and NT samples. 
```{r age, fig.width=5, fig.height=4}
# make sure it is numeric
sample_data(ps_not_norm_comp)$Age..months. <- as.numeric(sample_data(ps_not_norm_comp)$Age..months.)

# plot
ggplot(data=sample_data(ps_not_norm_comp), aes(x=phenotype, y=Age..months., fill=phenotype))+
  geom_boxplot(width=0.7, outlier.colour='white')+
  geom_jitter(size=1, position=position_jitter(width=0.1))+
  xlab('')+ylab('Age (months)')+
  scale_fill_manual(values=sgColorPalette)+
  theme_minimal()

# run tests to check significance
shapiro.test(sample_data(ps_not_norm_comp)$Age..months.) #not normal we need a reanking test
wilcox.test(Age..months. ~ phenotype, data=data.frame(sample_data(ps_not_norm_comp)), var.equal=FALSE)


#We see the NT have a much higher age range - this is likely to do with the way that we phrased the eligibility criteria - ASD child between the ages of 2 and 10 and a NT within 2 years of age
```
### Investigate family similarity using euclidean distance (parts taken from Random forest rmd)

```{r}
ps_deseq <- readRDS(paste0(output_data, "Filtered/ps_deseq_friedfilt.rds"))
ps_not_norm_comp <- readRDS("../data/ps_not_norm_age_filter_complete_family.rds")

#Remove Breastfed and their families
breast_fed <- c("089_A","054_N", "158_N" )

b_fed<-unique(ps_not_norm_comp@sam_data$Family.group.ID[which(ps_not_norm_comp@sam_data$Host.Name %in% breast_fed)])

#remove the whole family
for (i in b_fed){
  ps_not_norm_comp<- prune_samples(ps_not_norm_comp@sam_data$Family.group.ID != i, ps_not_norm_comp)

}


#Remove Possible Contradictions and their families
possible_phen_contra <- c("020_A","131_A", "184_A" )

p_con<-unique(ps_not_norm_comp@sam_data$Family.group.ID[which(ps_not_norm_comp@sam_data$Host.Name %in% possible_phen_contra)])

#remove the whole family
for (i in p_con){
  ps_not_norm_comp<- prune_samples(ps_not_norm_comp@sam_data$Family.group.ID != i, ps_not_norm_comp)

}

ps_deseq@sam_data<-sample_data(ps_not_norm_comp)

```


### Lifestyle_Variables for ML
```{r echo = F, results = 'hide'}
source('../clean_mapping_ml.R')
map_keep <- keepImportantColumns(ps_deseq@sam_data, metabol = F)
rownames(map_keep) <- map_keep$biospecimen_id
write.csv(map_keep, file = "../data/map_keep.csv")
map_keep<-read.csv(file = "../data/map_keep.csv", row.names = "X")

  
#Added makeFieldNumeric already in the filtering_normalization.rmd, so not needed here, so will omit
map_num <- makeFieldsNumeric(map_keep)
#select doesnt work for my session for some reason
#map_num <-map_num %>% select(-c(MARA, date))
map_num <- map_num[,-which(colnames(map_num) %in% c("MARA", "date"))]
nums <- as.vector(unlist(lapply(map_num, is.numeric)) )
map_num[, !nums] <- lapply(map_num[, !nums], factor)
map_num$stool_freq <- as.numeric(map_num$stool_freq)
map_keep <- map_num
boolean<- c("dog", "cat",  "gluten_allergy", "multivitamin", "env_tobacco", "dietary_supplement" )


freq_dict_3 <- list( "TRUE" = 1, "FALSE" = 0 )
  dict_3_items <- boolean
  for(item in dict_3_items){
    print(item)
    tmp <- rep(NA, nrow(map_keep))
    freqs <- handleNAs(map_keep[ , item])
    numeric_rep <- unlist(freq_dict_3[freqs])
    print(paste("Numeric rep length: ", length(numeric_rep)))
    print(sum(!is.na(freqs)))
    tmp[!is.na(freqs)] <- as.numeric(numeric_rep)
    tmp[is.na(tmp)] <- 1
    map_keep[ , item] <- tmp
  }


map_euc<- map_keep


nonlifestyle_objective<-c("biospecimen_id", "biospecimen_name" , "host_name" , "timepoint",  "min_time_antibiotics" , "stool_freq",  "csection", "racial_group" , "specific_food_allergy", "GI_issues_this_week" , "other_GI_symptoms" , "sex" , "specific_food_allergy", "nonceliac_sensitivity", "age" , "lactose_intolerance" , "prematurely_born", "dietary_restriction" , "diarrhea", "constipation" , "recently_ill", "father_age" ,  "mother_age", "familyID" , "MARA" , "date", "phenotype")

for_euc<-colnames(map_euc)[-which(colnames(map_euc) %in% nonlifestyle_objective)]

euc_data<-map_euc[, colnames(map_euc) %in% for_euc]

euc_distances<-dist(euc_data, method = "euclidean")

a<-as.vector(euc_distances)
all_distances<-a#[-which(as.vector(euc_distances) == 0)]

a<-as.data.frame(all_distances)
colnames(a) <- "Euclidean_Distance"

fam_averages <- list() 
for(i in unique(ps_deseq@sam_data$Family.group.ID)){
tmpps <- prune_samples((ps_deseq@sam_data$Family.group.ID == i), ps_deseq)
fam<-rownames(sample_data(tmpps))
fam_euc_data<-euc_data[rownames(euc_data) %in% fam,]
fam_distances<-dist(fam_euc_data, method = "euclidean")
fam_averages<-c(fam_averages, fam_distances[1])
}
line<-mean(unlist(fam_averages))
p <- ggplot(a, aes(x=Euclidean_Distance)) + 
  geom_density() + geom_vline(aes(xintercept=line),
            color="blue", linetype="dashed", size=1)
p


```




### insighnt into pet variables
```{r}
write.csv(metadata_ok, "../data/sam_data.csv")
map <- read.csv("../data/sam_data.csv", row.names = 1)
wilcox.test(Annual.household.income_rank ~ Outdoors.pet, data = map, var.equal = FALSE)


wilcox.test(Annual.household.income_rank ~ Pets.in.home, data = map, var.equal = FALSE)


```



